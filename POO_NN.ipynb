{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    # computes the output Y of a layer for a given input X\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # computes dE/dX for a given dE/dY (and update parameters if any)\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mon réseau de Neurones from scratch en POO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# une classe qui hérite la classe base (Layer) et permet de créer un fully Connected layer\n",
    "\n",
    "class FCLayer(Layer):\n",
    "    # input_size = number of input neurons\n",
    "    # output_size = number of output neurons\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(1, output_size) - 0.5\n",
    "\n",
    "    # returns output for a given input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    # computes dE/dW, dE/dB for a given output_error=dE/dY. Returns input_error=dE/dX.\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        # dBias = output_error\n",
    "\n",
    "        # update parameters\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  Une classe qui hérite de la classe layer et qui permet l'activation de chaque layer:\n",
    "\n",
    "Nous avons deux modes d'activations des layers: une pour la forward et une pour la backward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe qui hérite la classe base et permet de propager les activations de la forward et la backward \n",
    "\n",
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    # returns the activated input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    # Returns input_error=dE/dX for a given output_error=dE/dY.\n",
    "    # learning_rate is not used because there is no \"learnable\" parameters.\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function and its derivative\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1-np.tanh(x)**2\n",
    "\n",
    "def sigmoid(x):\n",
    "    z = np.exp(-x)\n",
    "    return 1 / (1+ z)\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and its derivative\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true-y_pred, 2))\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2 * (y_pred-y_true)/y_true.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La classe **Network** \n",
    "\n",
    "Permet de construire notre réseau et l'entrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "\n",
    "    # add layer to network\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    # set loss to use\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    # predict output for given input\n",
    "    def predict(self, input_data):\n",
    "        # sample dimension first\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "\n",
    "        # run network over all samples\n",
    "        for i in range(samples):\n",
    "            # forward propagation\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "\n",
    "    # train the network\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        # sample dimension first\n",
    "        samples = len(x_train)\n",
    "\n",
    "        # training loop\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                # forward propagation\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "\n",
    "                # compute loss (for display purpose only)\n",
    "                err += self.loss(y_train[j], output)\n",
    "\n",
    "                # backward propagation\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "\n",
    "            # calculate average error on all samples\n",
    "            err /= samples\n",
    "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainer les données XOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/500   error=0.726282\n",
      "epoch 2/500   error=0.352778\n",
      "epoch 3/500   error=0.313626\n",
      "epoch 4/500   error=0.306807\n",
      "epoch 5/500   error=0.304635\n",
      "epoch 6/500   error=0.303588\n",
      "epoch 7/500   error=0.302922\n",
      "epoch 8/500   error=0.302421\n",
      "epoch 9/500   error=0.302003\n",
      "epoch 10/500   error=0.301636\n",
      "epoch 11/500   error=0.301300\n",
      "epoch 12/500   error=0.300988\n",
      "epoch 13/500   error=0.300692\n",
      "epoch 14/500   error=0.300410\n",
      "epoch 15/500   error=0.300138\n",
      "epoch 16/500   error=0.299873\n",
      "epoch 17/500   error=0.299616\n",
      "epoch 18/500   error=0.299363\n",
      "epoch 19/500   error=0.299116\n",
      "epoch 20/500   error=0.298871\n",
      "epoch 21/500   error=0.298630\n",
      "epoch 22/500   error=0.298392\n",
      "epoch 23/500   error=0.298155\n",
      "epoch 24/500   error=0.297921\n",
      "epoch 25/500   error=0.297688\n",
      "epoch 26/500   error=0.297457\n",
      "epoch 27/500   error=0.297227\n",
      "epoch 28/500   error=0.296999\n",
      "epoch 29/500   error=0.296772\n",
      "epoch 30/500   error=0.296546\n",
      "epoch 31/500   error=0.296320\n",
      "epoch 32/500   error=0.296096\n",
      "epoch 33/500   error=0.295873\n",
      "epoch 34/500   error=0.295650\n",
      "epoch 35/500   error=0.295428\n",
      "epoch 36/500   error=0.295206\n",
      "epoch 37/500   error=0.294985\n",
      "epoch 38/500   error=0.294765\n",
      "epoch 39/500   error=0.294545\n",
      "epoch 40/500   error=0.294325\n",
      "epoch 41/500   error=0.294105\n",
      "epoch 42/500   error=0.293886\n",
      "epoch 43/500   error=0.293666\n",
      "epoch 44/500   error=0.293447\n",
      "epoch 45/500   error=0.293227\n",
      "epoch 46/500   error=0.293008\n",
      "epoch 47/500   error=0.292787\n",
      "epoch 48/500   error=0.292567\n",
      "epoch 49/500   error=0.292346\n",
      "epoch 50/500   error=0.292124\n",
      "epoch 51/500   error=0.291901\n",
      "epoch 52/500   error=0.291678\n",
      "epoch 53/500   error=0.291453\n",
      "epoch 54/500   error=0.291228\n",
      "epoch 55/500   error=0.291001\n",
      "epoch 56/500   error=0.290773\n",
      "epoch 57/500   error=0.290543\n",
      "epoch 58/500   error=0.290312\n",
      "epoch 59/500   error=0.290079\n",
      "epoch 60/500   error=0.289844\n",
      "epoch 61/500   error=0.289607\n",
      "epoch 62/500   error=0.289368\n",
      "epoch 63/500   error=0.289126\n",
      "epoch 64/500   error=0.288882\n",
      "epoch 65/500   error=0.288634\n",
      "epoch 66/500   error=0.288384\n",
      "epoch 67/500   error=0.288131\n",
      "epoch 68/500   error=0.287874\n",
      "epoch 69/500   error=0.287613\n",
      "epoch 70/500   error=0.287349\n",
      "epoch 71/500   error=0.287080\n",
      "epoch 72/500   error=0.286807\n",
      "epoch 73/500   error=0.286529\n",
      "epoch 74/500   error=0.286246\n",
      "epoch 75/500   error=0.285957\n",
      "epoch 76/500   error=0.285662\n",
      "epoch 77/500   error=0.285361\n",
      "epoch 78/500   error=0.285054\n",
      "epoch 79/500   error=0.284739\n",
      "epoch 80/500   error=0.284416\n",
      "epoch 81/500   error=0.284085\n",
      "epoch 82/500   error=0.283745\n",
      "epoch 83/500   error=0.283396\n",
      "epoch 84/500   error=0.283036\n",
      "epoch 85/500   error=0.282665\n",
      "epoch 86/500   error=0.282282\n",
      "epoch 87/500   error=0.281887\n",
      "epoch 88/500   error=0.281478\n",
      "epoch 89/500   error=0.281053\n",
      "epoch 90/500   error=0.280613\n",
      "epoch 91/500   error=0.280155\n",
      "epoch 92/500   error=0.279679\n",
      "epoch 93/500   error=0.279182\n",
      "epoch 94/500   error=0.278664\n",
      "epoch 95/500   error=0.278121\n",
      "epoch 96/500   error=0.277554\n",
      "epoch 97/500   error=0.276958\n",
      "epoch 98/500   error=0.276332\n",
      "epoch 99/500   error=0.275674\n",
      "epoch 100/500   error=0.274980\n",
      "epoch 101/500   error=0.274248\n",
      "epoch 102/500   error=0.273475\n",
      "epoch 103/500   error=0.272656\n",
      "epoch 104/500   error=0.271790\n",
      "epoch 105/500   error=0.270871\n",
      "epoch 106/500   error=0.269896\n",
      "epoch 107/500   error=0.268861\n",
      "epoch 108/500   error=0.267760\n",
      "epoch 109/500   error=0.266589\n",
      "epoch 110/500   error=0.265343\n",
      "epoch 111/500   error=0.264018\n",
      "epoch 112/500   error=0.262609\n",
      "epoch 113/500   error=0.261111\n",
      "epoch 114/500   error=0.259519\n",
      "epoch 115/500   error=0.257830\n",
      "epoch 116/500   error=0.256042\n",
      "epoch 117/500   error=0.254151\n",
      "epoch 118/500   error=0.252158\n",
      "epoch 119/500   error=0.250065\n",
      "epoch 120/500   error=0.247873\n",
      "epoch 121/500   error=0.245590\n",
      "epoch 122/500   error=0.243223\n",
      "epoch 123/500   error=0.240784\n",
      "epoch 124/500   error=0.238288\n",
      "epoch 125/500   error=0.235751\n",
      "epoch 126/500   error=0.233193\n",
      "epoch 127/500   error=0.230635\n",
      "epoch 128/500   error=0.228098\n",
      "epoch 129/500   error=0.225606\n",
      "epoch 130/500   error=0.223177\n",
      "epoch 131/500   error=0.220829\n",
      "epoch 132/500   error=0.218578\n",
      "epoch 133/500   error=0.216435\n",
      "epoch 134/500   error=0.214406\n",
      "epoch 135/500   error=0.212495\n",
      "epoch 136/500   error=0.210703\n",
      "epoch 137/500   error=0.209027\n",
      "epoch 138/500   error=0.207463\n",
      "epoch 139/500   error=0.206004\n",
      "epoch 140/500   error=0.204645\n",
      "epoch 141/500   error=0.203377\n",
      "epoch 142/500   error=0.202193\n",
      "epoch 143/500   error=0.201087\n",
      "epoch 144/500   error=0.200050\n",
      "epoch 145/500   error=0.199077\n",
      "epoch 146/500   error=0.198161\n",
      "epoch 147/500   error=0.197298\n",
      "epoch 148/500   error=0.196481\n",
      "epoch 149/500   error=0.195707\n",
      "epoch 150/500   error=0.194972\n",
      "epoch 151/500   error=0.194271\n",
      "epoch 152/500   error=0.193601\n",
      "epoch 153/500   error=0.192959\n",
      "epoch 154/500   error=0.192343\n",
      "epoch 155/500   error=0.191749\n",
      "epoch 156/500   error=0.191177\n",
      "epoch 157/500   error=0.190624\n",
      "epoch 158/500   error=0.190088\n",
      "epoch 159/500   error=0.189567\n",
      "epoch 160/500   error=0.189062\n",
      "epoch 161/500   error=0.188569\n",
      "epoch 162/500   error=0.188089\n",
      "epoch 163/500   error=0.187620\n",
      "epoch 164/500   error=0.187162\n",
      "epoch 165/500   error=0.186714\n",
      "epoch 166/500   error=0.186275\n",
      "epoch 167/500   error=0.185844\n",
      "epoch 168/500   error=0.185422\n",
      "epoch 169/500   error=0.185008\n",
      "epoch 170/500   error=0.184601\n",
      "epoch 171/500   error=0.184202\n",
      "epoch 172/500   error=0.183808\n",
      "epoch 173/500   error=0.183422\n",
      "epoch 174/500   error=0.183041\n",
      "epoch 175/500   error=0.182666\n",
      "epoch 176/500   error=0.182296\n",
      "epoch 177/500   error=0.181932\n",
      "epoch 178/500   error=0.181572\n",
      "epoch 179/500   error=0.181217\n",
      "epoch 180/500   error=0.180866\n",
      "epoch 181/500   error=0.180519\n",
      "epoch 182/500   error=0.180176\n",
      "epoch 183/500   error=0.179836\n",
      "epoch 184/500   error=0.179499\n",
      "epoch 185/500   error=0.179165\n",
      "epoch 186/500   error=0.178834\n",
      "epoch 187/500   error=0.178504\n",
      "epoch 188/500   error=0.178176\n",
      "epoch 189/500   error=0.177849\n",
      "epoch 190/500   error=0.177523\n",
      "epoch 191/500   error=0.177198\n",
      "epoch 192/500   error=0.176873\n",
      "epoch 193/500   error=0.176547\n",
      "epoch 194/500   error=0.176220\n",
      "epoch 195/500   error=0.175891\n",
      "epoch 196/500   error=0.175560\n",
      "epoch 197/500   error=0.175226\n",
      "epoch 198/500   error=0.174888\n",
      "epoch 199/500   error=0.174546\n",
      "epoch 200/500   error=0.174198\n",
      "epoch 201/500   error=0.173844\n",
      "epoch 202/500   error=0.173482\n",
      "epoch 203/500   error=0.173111\n",
      "epoch 204/500   error=0.172730\n",
      "epoch 205/500   error=0.172337\n",
      "epoch 206/500   error=0.171931\n",
      "epoch 207/500   error=0.171509\n",
      "epoch 208/500   error=0.171069\n",
      "epoch 209/500   error=0.170608\n",
      "epoch 210/500   error=0.170124\n",
      "epoch 211/500   error=0.169613\n",
      "epoch 212/500   error=0.169071\n",
      "epoch 213/500   error=0.168494\n",
      "epoch 214/500   error=0.167876\n",
      "epoch 215/500   error=0.167210\n",
      "epoch 216/500   error=0.166491\n",
      "epoch 217/500   error=0.165708\n",
      "epoch 218/500   error=0.164852\n",
      "epoch 219/500   error=0.163911\n",
      "epoch 220/500   error=0.162871\n",
      "epoch 221/500   error=0.161715\n",
      "epoch 222/500   error=0.160422\n",
      "epoch 223/500   error=0.158969\n",
      "epoch 224/500   error=0.157326\n",
      "epoch 225/500   error=0.155461\n",
      "epoch 226/500   error=0.153332\n",
      "epoch 227/500   error=0.150893\n",
      "epoch 228/500   error=0.148087\n",
      "epoch 229/500   error=0.144851\n",
      "epoch 230/500   error=0.141111\n",
      "epoch 231/500   error=0.136789\n",
      "epoch 232/500   error=0.131798\n",
      "epoch 233/500   error=0.126054\n",
      "epoch 234/500   error=0.119483\n",
      "epoch 235/500   error=0.112035\n",
      "epoch 236/500   error=0.103709\n",
      "epoch 237/500   error=0.094582\n",
      "epoch 238/500   error=0.084839\n",
      "epoch 239/500   error=0.074789\n",
      "epoch 240/500   error=0.064843\n",
      "epoch 241/500   error=0.055453\n",
      "epoch 242/500   error=0.047010\n",
      "epoch 243/500   error=0.039758\n",
      "epoch 244/500   error=0.033754\n",
      "epoch 245/500   error=0.028901\n",
      "epoch 246/500   error=0.025020\n",
      "epoch 247/500   error=0.021913\n",
      "epoch 248/500   error=0.019406\n",
      "epoch 249/500   error=0.017359\n",
      "epoch 250/500   error=0.015666\n",
      "epoch 251/500   error=0.014249\n",
      "epoch 252/500   error=0.013050\n",
      "epoch 253/500   error=0.012023\n",
      "epoch 254/500   error=0.011135\n",
      "epoch 255/500   error=0.010362\n",
      "epoch 256/500   error=0.009683\n",
      "epoch 257/500   error=0.009082\n",
      "epoch 258/500   error=0.008546\n",
      "epoch 259/500   error=0.008067\n",
      "epoch 260/500   error=0.007636\n",
      "epoch 261/500   error=0.007246\n",
      "epoch 262/500   error=0.006891\n",
      "epoch 263/500   error=0.006568\n",
      "epoch 264/500   error=0.006272\n",
      "epoch 265/500   error=0.006000\n",
      "epoch 266/500   error=0.005749\n",
      "epoch 267/500   error=0.005517\n",
      "epoch 268/500   error=0.005303\n",
      "epoch 269/500   error=0.005103\n",
      "epoch 270/500   error=0.004917\n",
      "epoch 271/500   error=0.004743\n",
      "epoch 272/500   error=0.004581\n",
      "epoch 273/500   error=0.004429\n",
      "epoch 274/500   error=0.004285\n",
      "epoch 275/500   error=0.004151\n",
      "epoch 276/500   error=0.004024\n",
      "epoch 277/500   error=0.003904\n",
      "epoch 278/500   error=0.003791\n",
      "epoch 279/500   error=0.003684\n",
      "epoch 280/500   error=0.003582\n",
      "epoch 281/500   error=0.003486\n",
      "epoch 282/500   error=0.003394\n",
      "epoch 283/500   error=0.003307\n",
      "epoch 284/500   error=0.003224\n",
      "epoch 285/500   error=0.003144\n",
      "epoch 286/500   error=0.003069\n",
      "epoch 287/500   error=0.002996\n",
      "epoch 288/500   error=0.002927\n",
      "epoch 289/500   error=0.002861\n",
      "epoch 290/500   error=0.002797\n",
      "epoch 291/500   error=0.002737\n",
      "epoch 292/500   error=0.002678\n",
      "epoch 293/500   error=0.002622\n",
      "epoch 294/500   error=0.002568\n",
      "epoch 295/500   error=0.002516\n",
      "epoch 296/500   error=0.002466\n",
      "epoch 297/500   error=0.002418\n",
      "epoch 298/500   error=0.002372\n",
      "epoch 299/500   error=0.002327\n",
      "epoch 300/500   error=0.002284\n",
      "epoch 301/500   error=0.002242\n",
      "epoch 302/500   error=0.002202\n",
      "epoch 303/500   error=0.002163\n",
      "epoch 304/500   error=0.002126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 305/500   error=0.002089\n",
      "epoch 306/500   error=0.002054\n",
      "epoch 307/500   error=0.002020\n",
      "epoch 308/500   error=0.001987\n",
      "epoch 309/500   error=0.001955\n",
      "epoch 310/500   error=0.001924\n",
      "epoch 311/500   error=0.001894\n",
      "epoch 312/500   error=0.001864\n",
      "epoch 313/500   error=0.001836\n",
      "epoch 314/500   error=0.001808\n",
      "epoch 315/500   error=0.001781\n",
      "epoch 316/500   error=0.001755\n",
      "epoch 317/500   error=0.001730\n",
      "epoch 318/500   error=0.001705\n",
      "epoch 319/500   error=0.001681\n",
      "epoch 320/500   error=0.001658\n",
      "epoch 321/500   error=0.001635\n",
      "epoch 322/500   error=0.001613\n",
      "epoch 323/500   error=0.001591\n",
      "epoch 324/500   error=0.001570\n",
      "epoch 325/500   error=0.001549\n",
      "epoch 326/500   error=0.001529\n",
      "epoch 327/500   error=0.001510\n",
      "epoch 328/500   error=0.001490\n",
      "epoch 329/500   error=0.001472\n",
      "epoch 330/500   error=0.001454\n",
      "epoch 331/500   error=0.001436\n",
      "epoch 332/500   error=0.001418\n",
      "epoch 333/500   error=0.001401\n",
      "epoch 334/500   error=0.001385\n",
      "epoch 335/500   error=0.001368\n",
      "epoch 336/500   error=0.001353\n",
      "epoch 337/500   error=0.001337\n",
      "epoch 338/500   error=0.001322\n",
      "epoch 339/500   error=0.001307\n",
      "epoch 340/500   error=0.001292\n",
      "epoch 341/500   error=0.001278\n",
      "epoch 342/500   error=0.001264\n",
      "epoch 343/500   error=0.001250\n",
      "epoch 344/500   error=0.001237\n",
      "epoch 345/500   error=0.001224\n",
      "epoch 346/500   error=0.001211\n",
      "epoch 347/500   error=0.001198\n",
      "epoch 348/500   error=0.001186\n",
      "epoch 349/500   error=0.001174\n",
      "epoch 350/500   error=0.001162\n",
      "epoch 351/500   error=0.001150\n",
      "epoch 352/500   error=0.001139\n",
      "epoch 353/500   error=0.001128\n",
      "epoch 354/500   error=0.001117\n",
      "epoch 355/500   error=0.001106\n",
      "epoch 356/500   error=0.001095\n",
      "epoch 357/500   error=0.001085\n",
      "epoch 358/500   error=0.001075\n",
      "epoch 359/500   error=0.001064\n",
      "epoch 360/500   error=0.001055\n",
      "epoch 361/500   error=0.001045\n",
      "epoch 362/500   error=0.001035\n",
      "epoch 363/500   error=0.001026\n",
      "epoch 364/500   error=0.001017\n",
      "epoch 365/500   error=0.001008\n",
      "epoch 366/500   error=0.000999\n",
      "epoch 367/500   error=0.000990\n",
      "epoch 368/500   error=0.000981\n",
      "epoch 369/500   error=0.000973\n",
      "epoch 370/500   error=0.000965\n",
      "epoch 371/500   error=0.000956\n",
      "epoch 372/500   error=0.000948\n",
      "epoch 373/500   error=0.000940\n",
      "epoch 374/500   error=0.000933\n",
      "epoch 375/500   error=0.000925\n",
      "epoch 376/500   error=0.000917\n",
      "epoch 377/500   error=0.000910\n",
      "epoch 378/500   error=0.000902\n",
      "epoch 379/500   error=0.000895\n",
      "epoch 380/500   error=0.000888\n",
      "epoch 381/500   error=0.000881\n",
      "epoch 382/500   error=0.000874\n",
      "epoch 383/500   error=0.000867\n",
      "epoch 384/500   error=0.000861\n",
      "epoch 385/500   error=0.000854\n",
      "epoch 386/500   error=0.000848\n",
      "epoch 387/500   error=0.000841\n",
      "epoch 388/500   error=0.000835\n",
      "epoch 389/500   error=0.000829\n",
      "epoch 390/500   error=0.000822\n",
      "epoch 391/500   error=0.000816\n",
      "epoch 392/500   error=0.000810\n",
      "epoch 393/500   error=0.000804\n",
      "epoch 394/500   error=0.000799\n",
      "epoch 395/500   error=0.000793\n",
      "epoch 396/500   error=0.000787\n",
      "epoch 397/500   error=0.000782\n",
      "epoch 398/500   error=0.000776\n",
      "epoch 399/500   error=0.000771\n",
      "epoch 400/500   error=0.000765\n",
      "epoch 401/500   error=0.000760\n",
      "epoch 402/500   error=0.000755\n",
      "epoch 403/500   error=0.000750\n",
      "epoch 404/500   error=0.000745\n",
      "epoch 405/500   error=0.000740\n",
      "epoch 406/500   error=0.000735\n",
      "epoch 407/500   error=0.000730\n",
      "epoch 408/500   error=0.000725\n",
      "epoch 409/500   error=0.000720\n",
      "epoch 410/500   error=0.000715\n",
      "epoch 411/500   error=0.000711\n",
      "epoch 412/500   error=0.000706\n",
      "epoch 413/500   error=0.000702\n",
      "epoch 414/500   error=0.000697\n",
      "epoch 415/500   error=0.000693\n",
      "epoch 416/500   error=0.000688\n",
      "epoch 417/500   error=0.000684\n",
      "epoch 418/500   error=0.000680\n",
      "epoch 419/500   error=0.000676\n",
      "epoch 420/500   error=0.000671\n",
      "epoch 421/500   error=0.000667\n",
      "epoch 422/500   error=0.000663\n",
      "epoch 423/500   error=0.000659\n",
      "epoch 424/500   error=0.000655\n",
      "epoch 425/500   error=0.000651\n",
      "epoch 426/500   error=0.000647\n",
      "epoch 427/500   error=0.000644\n",
      "epoch 428/500   error=0.000640\n",
      "epoch 429/500   error=0.000636\n",
      "epoch 430/500   error=0.000632\n",
      "epoch 431/500   error=0.000629\n",
      "epoch 432/500   error=0.000625\n",
      "epoch 433/500   error=0.000621\n",
      "epoch 434/500   error=0.000618\n",
      "epoch 435/500   error=0.000614\n",
      "epoch 436/500   error=0.000611\n",
      "epoch 437/500   error=0.000607\n",
      "epoch 438/500   error=0.000604\n",
      "epoch 439/500   error=0.000601\n",
      "epoch 440/500   error=0.000597\n",
      "epoch 441/500   error=0.000594\n",
      "epoch 442/500   error=0.000591\n",
      "epoch 443/500   error=0.000587\n",
      "epoch 444/500   error=0.000584\n",
      "epoch 445/500   error=0.000581\n",
      "epoch 446/500   error=0.000578\n",
      "epoch 447/500   error=0.000575\n",
      "epoch 448/500   error=0.000572\n",
      "epoch 449/500   error=0.000569\n",
      "epoch 450/500   error=0.000566\n",
      "epoch 451/500   error=0.000563\n",
      "epoch 452/500   error=0.000560\n",
      "epoch 453/500   error=0.000557\n",
      "epoch 454/500   error=0.000554\n",
      "epoch 455/500   error=0.000551\n",
      "epoch 456/500   error=0.000548\n",
      "epoch 457/500   error=0.000546\n",
      "epoch 458/500   error=0.000543\n",
      "epoch 459/500   error=0.000540\n",
      "epoch 460/500   error=0.000537\n",
      "epoch 461/500   error=0.000535\n",
      "epoch 462/500   error=0.000532\n",
      "epoch 463/500   error=0.000529\n",
      "epoch 464/500   error=0.000527\n",
      "epoch 465/500   error=0.000524\n",
      "epoch 466/500   error=0.000521\n",
      "epoch 467/500   error=0.000519\n",
      "epoch 468/500   error=0.000516\n",
      "epoch 469/500   error=0.000514\n",
      "epoch 470/500   error=0.000511\n",
      "epoch 471/500   error=0.000509\n",
      "epoch 472/500   error=0.000507\n",
      "epoch 473/500   error=0.000504\n",
      "epoch 474/500   error=0.000502\n",
      "epoch 475/500   error=0.000499\n",
      "epoch 476/500   error=0.000497\n",
      "epoch 477/500   error=0.000495\n",
      "epoch 478/500   error=0.000492\n",
      "epoch 479/500   error=0.000490\n",
      "epoch 480/500   error=0.000488\n",
      "epoch 481/500   error=0.000486\n",
      "epoch 482/500   error=0.000483\n",
      "epoch 483/500   error=0.000481\n",
      "epoch 484/500   error=0.000479\n",
      "epoch 485/500   error=0.000477\n",
      "epoch 486/500   error=0.000475\n",
      "epoch 487/500   error=0.000473\n",
      "epoch 488/500   error=0.000470\n",
      "epoch 489/500   error=0.000468\n",
      "epoch 490/500   error=0.000466\n",
      "epoch 491/500   error=0.000464\n",
      "epoch 492/500   error=0.000462\n",
      "epoch 493/500   error=0.000460\n",
      "epoch 494/500   error=0.000458\n",
      "epoch 495/500   error=0.000456\n",
      "epoch 496/500   error=0.000454\n",
      "epoch 497/500   error=0.000452\n",
      "epoch 498/500   error=0.000450\n",
      "epoch 499/500   error=0.000448\n",
      "epoch 500/500   error=0.000446\n",
      "[array([[0.00138964]]), array([[0.97498626]]), array([[0.96616693]]), array([[-0.00240736]])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#training data\n",
    "\n",
    "x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
    "y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
    "# print(x_train)\n",
    "# print(y_train)\n",
    "\n",
    "# network\n",
    "net = Network()\n",
    "net.add(FCLayer(2, 3))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FCLayer(3, 3))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FCLayer(3, 1))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "\n",
    "# train\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(x_train, y_train, epochs=500, learning_rate=0.1)\n",
    "\n",
    "# test\n",
    "out = net.predict(x_train)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
